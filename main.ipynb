{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "EHcjGzSSsTKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "XL53k4pksSYq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Loading dataset"
      ],
      "metadata": {
        "id": "kAaKISGqsJOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "# Data URL\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "pS8KMnDesJOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n"
      ],
      "metadata": {
        "id": "Kzbs3H2GsJOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xo10AvfxsJOc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "o2KfWp6lsJOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ],
      "metadata": {
        "id": "Fk3qTCThsJOf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout[0][0]',                \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 500, 4)       0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 500, 1)       5           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 500, 4)       0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 500, 1)       5           ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 500, 4)       0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 500, 1)       5           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 500, 4)       0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 500, 1)       5           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          64128       ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 93,130\n",
            "Trainable params: 93,130\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "45/45 [==============================] - 36s 483ms/step - loss: 1.0165 - sparse_categorical_accuracy: 0.5292 - val_loss: 0.7554 - val_sparse_categorical_accuracy: 0.5659\n",
            "Epoch 2/200\n",
            "45/45 [==============================] - 22s 483ms/step - loss: 0.8542 - sparse_categorical_accuracy: 0.5615 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.6103\n",
            "Epoch 3/200\n",
            "45/45 [==============================] - 22s 488ms/step - loss: 0.7798 - sparse_categorical_accuracy: 0.6045 - val_loss: 0.6470 - val_sparse_categorical_accuracy: 0.6477\n",
            "Epoch 4/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.7249 - sparse_categorical_accuracy: 0.6260 - val_loss: 0.6250 - val_sparse_categorical_accuracy: 0.6560\n",
            "Epoch 5/200\n",
            "45/45 [==============================] - 23s 503ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.6507 - val_loss: 0.6016 - val_sparse_categorical_accuracy: 0.6852\n",
            "Epoch 6/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.6757 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.6921\n",
            "Epoch 7/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.6123 - sparse_categorical_accuracy: 0.6851 - val_loss: 0.5812 - val_sparse_categorical_accuracy: 0.6949\n",
            "Epoch 8/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.6088 - sparse_categorical_accuracy: 0.6858 - val_loss: 0.5726 - val_sparse_categorical_accuracy: 0.7087\n",
            "Epoch 9/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.5999 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.5628 - val_sparse_categorical_accuracy: 0.7157\n",
            "Epoch 10/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.5569 - val_sparse_categorical_accuracy: 0.7254\n",
            "Epoch 11/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.5468 - val_sparse_categorical_accuracy: 0.7323\n",
            "Epoch 12/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 13/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.7448 - val_loss: 0.5375 - val_sparse_categorical_accuracy: 0.7448\n",
            "Epoch 14/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.5003 - sparse_categorical_accuracy: 0.7590 - val_loss: 0.5347 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 15/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.4843 - sparse_categorical_accuracy: 0.7712 - val_loss: 0.5248 - val_sparse_categorical_accuracy: 0.7490\n",
            "Epoch 16/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4823 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.5173 - val_sparse_categorical_accuracy: 0.7434\n",
            "Epoch 17/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4747 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.5156 - val_sparse_categorical_accuracy: 0.7503\n",
            "Epoch 18/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.4650 - sparse_categorical_accuracy: 0.7774 - val_loss: 0.5097 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 19/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.4614 - sparse_categorical_accuracy: 0.7872 - val_loss: 0.5079 - val_sparse_categorical_accuracy: 0.7462\n",
            "Epoch 20/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7889 - val_loss: 0.5044 - val_sparse_categorical_accuracy: 0.7517\n",
            "Epoch 21/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.4391 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.4976 - val_sparse_categorical_accuracy: 0.7545\n",
            "Epoch 22/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.7642\n",
            "Epoch 23/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.4968 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 24/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4040 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.7753\n",
            "Epoch 25/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4135 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4832 - val_sparse_categorical_accuracy: 0.7725\n",
            "Epoch 26/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.4800 - val_sparse_categorical_accuracy: 0.7767\n",
            "Epoch 27/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3867 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.4806 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 28/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3839 - sparse_categorical_accuracy: 0.8358 - val_loss: 0.4752 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 29/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3843 - sparse_categorical_accuracy: 0.8337 - val_loss: 0.4726 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 30/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8382 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.7809\n",
            "Epoch 31/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3692 - sparse_categorical_accuracy: 0.8403 - val_loss: 0.4681 - val_sparse_categorical_accuracy: 0.7809\n",
            "Epoch 32/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.3635 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.4610 - val_sparse_categorical_accuracy: 0.7864\n",
            "Epoch 33/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.3525 - sparse_categorical_accuracy: 0.8524 - val_loss: 0.4576 - val_sparse_categorical_accuracy: 0.7795\n",
            "Epoch 34/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.8545 - val_loss: 0.4572 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 35/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.3484 - sparse_categorical_accuracy: 0.8517 - val_loss: 0.4549 - val_sparse_categorical_accuracy: 0.7822\n",
            "Epoch 36/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.4531 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 37/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3356 - sparse_categorical_accuracy: 0.8608 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 38/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3420 - sparse_categorical_accuracy: 0.8528 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.7933\n",
            "Epoch 39/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3346 - sparse_categorical_accuracy: 0.8608 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.7961\n",
            "Epoch 40/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3227 - sparse_categorical_accuracy: 0.8788 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.7920\n",
            "Epoch 41/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3240 - sparse_categorical_accuracy: 0.8701 - val_loss: 0.4416 - val_sparse_categorical_accuracy: 0.7933\n",
            "Epoch 42/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.3213 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.4362 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 43/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.3132 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 44/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3119 - sparse_categorical_accuracy: 0.8767 - val_loss: 0.4311 - val_sparse_categorical_accuracy: 0.7989\n",
            "Epoch 45/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3029 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.4317 - val_sparse_categorical_accuracy: 0.8017\n",
            "Epoch 46/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.4287 - val_sparse_categorical_accuracy: 0.8003\n",
            "Epoch 47/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.8806 - val_loss: 0.4272 - val_sparse_categorical_accuracy: 0.8058\n",
            "Epoch 48/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.8806 - val_loss: 0.4256 - val_sparse_categorical_accuracy: 0.8072\n",
            "Epoch 49/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2903 - sparse_categorical_accuracy: 0.8837 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.8031\n",
            "Epoch 50/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.4185 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 51/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2797 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 52/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2749 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.4180 - val_sparse_categorical_accuracy: 0.8058\n",
            "Epoch 53/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.4147 - val_sparse_categorical_accuracy: 0.8086\n",
            "Epoch 54/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2815 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.4119 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 55/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.4151 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 56/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2649 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4104 - val_sparse_categorical_accuracy: 0.8183\n",
            "Epoch 57/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2560 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.4076 - val_sparse_categorical_accuracy: 0.8141\n",
            "Epoch 58/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2631 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.4089 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 59/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2636 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.8114\n",
            "Epoch 60/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2483 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.3999 - val_sparse_categorical_accuracy: 0.8155\n",
            "Epoch 61/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2583 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.3998 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 62/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2501 - sparse_categorical_accuracy: 0.9108 - val_loss: 0.3976 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 63/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2402 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.3950 - val_sparse_categorical_accuracy: 0.8225\n",
            "Epoch 64/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2423 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.3957 - val_sparse_categorical_accuracy: 0.8239\n",
            "Epoch 65/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2484 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8252\n",
            "Epoch 66/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2395 - sparse_categorical_accuracy: 0.9115 - val_loss: 0.3901 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 67/200\n",
            "45/45 [==============================] - 22s 501ms/step - loss: 0.2314 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8211\n",
            "Epoch 68/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3865 - val_sparse_categorical_accuracy: 0.8294\n",
            "Epoch 69/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.3862 - val_sparse_categorical_accuracy: 0.8280\n",
            "Epoch 70/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2320 - sparse_categorical_accuracy: 0.9170 - val_loss: 0.3849 - val_sparse_categorical_accuracy: 0.8266\n",
            "Epoch 71/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.3843 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 72/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.3817 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 73/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2303 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.3784 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 74/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2162 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3803 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 75/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2190 - sparse_categorical_accuracy: 0.9174 - val_loss: 0.3801 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 76/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2146 - sparse_categorical_accuracy: 0.9226 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 77/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.3775 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 78/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2098 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.3767 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 79/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9194 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 80/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.2098 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 81/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2103 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 82/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.1974 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.3727 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 83/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.2056 - sparse_categorical_accuracy: 0.9292 - val_loss: 0.3699 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 84/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1973 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 85/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.3642 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 86/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1879 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3662 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 87/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.2040 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 88/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.3690 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 89/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.3660 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 90/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1870 - sparse_categorical_accuracy: 0.9385 - val_loss: 0.3625 - val_sparse_categorical_accuracy: 0.8322\n",
            "Epoch 91/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1901 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.3595 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 92/200\n",
            "45/45 [==============================] - 22s 501ms/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 93/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1924 - sparse_categorical_accuracy: 0.9316 - val_loss: 0.3607 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 94/200\n",
            "45/45 [==============================] - 22s 497ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.3622 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 95/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3647 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 96/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1786 - sparse_categorical_accuracy: 0.9424 - val_loss: 0.3662 - val_sparse_categorical_accuracy: 0.8377\n",
            "Epoch 97/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9330 - val_loss: 0.3568 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 98/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1696 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.3602 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 99/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9351 - val_loss: 0.3637 - val_sparse_categorical_accuracy: 0.8350\n",
            "Epoch 100/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1777 - sparse_categorical_accuracy: 0.9368 - val_loss: 0.3620 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 101/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1702 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.3583 - val_sparse_categorical_accuracy: 0.8419\n",
            "Epoch 102/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1737 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.3569 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 103/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1631 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 104/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1641 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.3578 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 105/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.3529 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 106/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9420 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 107/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1612 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.3555 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 108/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1576 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 109/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.3549 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 110/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3558 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 111/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.3565 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 112/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1556 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.3532 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 113/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1516 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 114/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3555 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 115/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1545 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 116/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.3513 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 117/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.3584 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 118/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.3513 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 119/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 120/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.3540 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 121/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1483 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3495 - val_sparse_categorical_accuracy: 0.8391\n",
            "Epoch 122/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1413 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3553 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 123/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1444 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.3516 - val_sparse_categorical_accuracy: 0.8433\n",
            "Epoch 124/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9448 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8460\n",
            "Epoch 125/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1423 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 126/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3519 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 127/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8447\n",
            "Epoch 128/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1360 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.3484 - val_sparse_categorical_accuracy: 0.8488\n",
            "Epoch 129/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 0.8502\n",
            "Epoch 130/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1345 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 131/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1366 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8585\n",
            "Epoch 132/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.3459 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 133/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.3489 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 134/200\n",
            "45/45 [==============================] - 23s 501ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.3444 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 135/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1335 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.3427 - val_sparse_categorical_accuracy: 0.8558\n",
            "Epoch 136/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.3507 - val_sparse_categorical_accuracy: 0.8571\n",
            "Epoch 137/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8474\n",
            "Epoch 138/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 139/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3469 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 140/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8516\n",
            "Epoch 141/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8530\n",
            "Epoch 142/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.3429 - val_sparse_categorical_accuracy: 0.8599\n",
            "Epoch 143/200\n",
            "45/45 [==============================] - 22s 498ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 144/200\n",
            "45/45 [==============================] - 22s 499ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.3439 - val_sparse_categorical_accuracy: 0.8544\n",
            "Epoch 145/200\n",
            "45/45 [==============================] - 22s 500ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.3476 - val_sparse_categorical_accuracy: 0.8571\n",
            "42/42 - 3s - loss: 0.3405 - sparse_categorical_accuracy: 0.8652 - 3s/epoch - 76ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34046512842178345, 0.8651515245437622]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "id": "2HnwxEVssJOg",
        "outputId": "d85ede67-3308-4a4d-8913-3db72764cd86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "timeseries_transformer_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}